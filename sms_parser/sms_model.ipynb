{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4739755f-b65b-4c05-b3bd-c7044fce2716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "csv_file  = 'sms.csv'\n",
    "print(spacy.__version__)\n",
    "\n",
    "\n",
    "def preprocess_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    training_data = []\n",
    "\n",
    "    for _, row in df.iterrows(): \n",
    "        text = row['sms']\n",
    "        entities = [] \n",
    "\n",
    "        # Extract entities without overlaps\n",
    "        start_amount = text.find(str(row['amount']))\n",
    "        end_amount = start_amount + len(str(row['amount']))\n",
    "        entities.append((start_amount, end_amount, 'amount'))\n",
    "\n",
    "        start_fees = text.find(str(row['fees']))\n",
    "        end_fees = start_fees + len(str(row['fees']))\n",
    "        entities.append((start_fees, end_fees, 'fees'))\n",
    "\n",
    "        start_date = text.find(row['date_time']) \n",
    "        end_date = start_date + len(row['date_time'])\n",
    "        entities.append((start_date, end_date, 'date_time')) \n",
    "        \n",
    "        start_transaction_type = text.find(row['transaction_type'])\n",
    "        end_transaction_type = start_transaction_type + len(row['transaction_type'])\n",
    "        entities.append((start_transaction_type, end_transaction_type, 'transaction_type'))\n",
    "        \n",
    "        start_receiver_sender = text.find(row['receiver_sender'])\n",
    "        end_receiver_sender = start_receiver_sender + len(row['receiver_sender'])\n",
    "        entities.append((start_receiver_sender, end_receiver_sender, 'receiver_sender'))\n",
    "\n",
    "        # Adjust entities to resolve overlaps\n",
    "        # For example, prioritize longer entities over shorter ones\n",
    "        adjusted_entities = resolve_overlaps(entities)\n",
    "\n",
    "        training_data.append((text, {\"entities\": adjusted_entities}))\n",
    "        biluo_tags = spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)\n",
    "        print(biluo_tags)\n",
    "\n",
    "    return training_data\n",
    "\n",
    "def resolve_overlaps(entities):\n",
    "    adjusted_entities = []\n",
    "    for start, end, label in entities:\n",
    "        # Check if the current entity overlaps with any previous entity\n",
    "        is_overlapping = any(start < prev_end and end > prev_start for prev_start, prev_end, _ in adjusted_entities)\n",
    "        if not is_overlapping:\n",
    "            # If no overlap, add the entity as is\n",
    "            adjusted_entities.append((start, end, label))\n",
    "        else:\n",
    "            # Resolve overlap based on prioritization or splitting\n",
    "            # For example, you can prioritize longer entities\n",
    "            prev_entity_length = sum(prev_end - prev_start for prev_start, prev_end, _ in adjusted_entities)\n",
    "            current_entity_length = end - start\n",
    "            if current_entity_length > prev_entity_length:\n",
    "                # Prioritize the current entity\n",
    "                adjusted_entities = [(s, e, l) for s, e, l in adjusted_entities if not (start < e and end > s)]\n",
    "                adjusted_entities.append((start, end, label))\n",
    "    \n",
    "    return adjusted_entities\n",
    "\n",
    "\n",
    "# def preprocess_data(csv_file):\n",
    "#     df = pd.read_csv(csv_file)\n",
    "#     training_data = []\n",
    "\n",
    "#     for _, row in df.iterrows(): \n",
    "#         text = row['sms']\n",
    "#         entities = [] \n",
    "\n",
    "#         start_amount = text.find(str(row['amount']))\n",
    "#         end_amount = start_amount + len(str(row['amount']))\n",
    "#         entities.append((start_amount, end_amount, 'amount'))\n",
    "\n",
    "#         start_fees = text.find(str(row['fees']))\n",
    "#         end_fees = start_fees + len(str(row['fees']))\n",
    "#         entities.append((start_fees, end_fees, 'fees'))\n",
    "\n",
    "#         start_date = text.find(row['date_time']) \n",
    "#         end_date = start_date + len(row['date_time'])\n",
    "#         entities.append((start_date, end_date, 'date_time')) \n",
    "        \n",
    "#         start_transaction_type = text.find(row['transaction_type'])\n",
    "#         end_transaction_type = start_transaction_type + len(row['transaction_type'])\n",
    "#         entities.append((start_transaction_type, end_transaction_type, 'transaction_type'))\n",
    "        \n",
    "#         start_receiver_sender = text.find(row['receiver_sender'])\n",
    "#         end_receiver_sender = start_receiver_sender + len(row['receiver_sender'])\n",
    "#         entities.append((start_receiver_sender, end_receiver_sender, 'receiver_sender'))\n",
    "\n",
    "#         training_data.append((text, {\"entities\": entities}))\n",
    "#     return training_data\n",
    "\n",
    "\n",
    "# def preprocess_data(csv_file):\n",
    "#     df = pd.read_csv(csv_file)\n",
    "#     training_data = []\n",
    "\n",
    "#     for _, row in df.iterrows(): \n",
    "#         text = row['sms']\n",
    "#         entities = [] \n",
    "\n",
    "#         start_amount = text.find(str(row['amount']))\n",
    "#         end_amount = start_amount + len(str(row['amount']))\n",
    "#         entities.append((start_amount, end_amount, 'amount'))\n",
    "\n",
    "#         start_fees = text.find(str(row['fees']))\n",
    "#         end_fees = start_fees + len(str(row['fees']))\n",
    "#         entities.append((start_fees, end_fees, 'fees'))\n",
    "\n",
    "#         start_date = text.find(row['date_time']) \n",
    "#         end_date = start_date + len(row['date_time'])\n",
    "#         entities.append((start_date, end_date, 'date_time')) \n",
    "        \n",
    "#         start_transaction_type = text.find(row['transaction_type'])\n",
    "#         end_transaction_type = start_transaction_type + len(row['transaction_type'])\n",
    "#         entities.append((start_transaction_type, end_transaction_type, 'transaction_type'))\n",
    "        \n",
    "\n",
    "#         # entities.append((text.find(str(row['amount'])), text.find(str(row['amount'])) + len(str(row['amount'])), 'amount'))\n",
    "#         # entities.append((text.find(row['transaction_type']), text.find(row['transaction_type']) + len(row['transaction_type']), 'transaction_type'))\n",
    "#         entities.append((text.find(row['receiver_sender']), text.find(row['receiver_sender']) + len(row['receiver_sender']), 'receiver_sender'))\n",
    "#         # entities.append((text.find(str(row['fees'])), text.find(str(row['fees'])) + len(str(row['fees'])), 'fees'))\n",
    "#         # entities.append((text.find(row['acccount']), text.find(row['acccount']) + len(row['acccount']), 'account'))\n",
    "#         # ... add more entities similarly (fees, account, receiver_sender)\n",
    "\n",
    "#         # training_data.append((text, {\"entities\": entities}))\n",
    "#         training_data.append((text, {\"spans\": entities}))\n",
    "#     return training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f442cc-5046-45dc-b1dd-16a7ae9dd794",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E103] Trying to set conflicting doc.ents: '(18, 23, 'amount')' and '(19, 20, 'fees')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# snapcat.add_label(\"account\")\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m nlp\u001b[38;5;241m.\u001b[39mbegin_training()\n\u001b[1;32m---> 16\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):  \u001b[38;5;66;03m# Example: Train for 20 iterations\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     examples \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(csv_file)\u001b[0m\n\u001b[0;32m     39\u001b[0m     adjusted_entities \u001b[38;5;241m=\u001b[39m resolve_overlaps(entities)\n\u001b[0;32m     41\u001b[0m     training_data\u001b[38;5;241m.\u001b[39mappend((text, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m\"\u001b[39m: adjusted_entities}))\n\u001b[1;32m---> 42\u001b[0m     biluo_tags \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffsets_to_biluo_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(biluo_tags)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m training_data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\spacy\\training\\iob_utils.py:114\u001b[0m, in \u001b[0;36moffsets_to_biluo_tags\u001b[1;34m(doc, entities, missing)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_char, end_char):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token_index \u001b[38;5;129;01min\u001b[39;00m tokens_in_ents\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             Errors\u001b[38;5;241m.\u001b[39mE103\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 span1\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    117\u001b[0m                     tokens_in_ents[token_index][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    118\u001b[0m                     tokens_in_ents[token_index][\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    119\u001b[0m                     tokens_in_ents[token_index][\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    120\u001b[0m                 ),\n\u001b[0;32m    121\u001b[0m                 span2\u001b[38;5;241m=\u001b[39m(start_char, end_char, label),\n\u001b[0;32m    122\u001b[0m             )\n\u001b[0;32m    123\u001b[0m         )\n\u001b[0;32m    124\u001b[0m     tokens_in_ents[token_index] \u001b[38;5;241m=\u001b[39m (start_char, end_char, label)\n\u001b[0;32m    125\u001b[0m start_token \u001b[38;5;241m=\u001b[39m starts\u001b[38;5;241m.\u001b[39mget(start_char)\n",
      "\u001b[1;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(18, 23, 'amount')' and '(19, 20, 'fees')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead."
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")  # Create a blank English model\n",
    "# ner = nlp.add_pipe(\"ner\")  # Add the NER component\n",
    "\n",
    "spancat = nlp.add_pipe(\"spancat\")\n",
    "\n",
    "\n",
    "# Add your custom labels\n",
    "spancat.add_label(\"date_time\")\n",
    "spancat.add_label(\"amount\")\n",
    "spancat.add_label(\"transaction_type\")\n",
    "spancat.add_label(\"receiver_sender\")\n",
    "spancat.add_label(\"fees\")\n",
    "# snapcat.add_label(\"account\")\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "training_data = preprocess_data(csv_file) \n",
    "\n",
    "for i in range(20):  # Example: Train for 20 iterations\n",
    "    examples = []\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        print(example)\n",
    "        examples.append(example)\n",
    "    nlp.update(examples, sgd=optimizer)\n",
    "nlp.to_disk(\"sms_parser_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ea26d5-eaae-4c5a-83ea-e2e7dd8a9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TxId: 13113290018. Your payment of 1,300 RWF to EMMANUELIE  UWIMANA 515867 has been completed at 2024-03-13 17:56:32. Your new balance: 2,002 RWF. Fee was 0 RWF\n",
      "{'carrier': 'M-Money'}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = spacy.load(\"sms_parser_model\")\n",
    "\n",
    "new_sms = \"TxId: 13113290018. Your payment of 1,300 RWF to EMMANUELIE  UWIMANA 515867 has been completed at 2024-03-13 17:56:32. Your new balance: 2,002 RWF. Fee was 0 RWF\"  \n",
    "carrier = \"M-Money\" # You'll provide this \n",
    "doc = loaded_model(new_sms)\n",
    "\n",
    "print(doc)\n",
    "extracted_data = {\n",
    "    \"carrier\": carrier    \n",
    "}\n",
    "\n",
    "for ent in doc.ents:\n",
    "    extracted_data[ent.label_] = ent.text \n",
    "\n",
    "print(extracted_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
